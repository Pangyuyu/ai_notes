# 备忘录

## MaxKb
- 简介   
  本地知识库
- docker

	```shell
	docker run -d --name=maxkb -p 8080:8080 -v ~/.maxkb:/var/lib/postgresql/data 1panel/maxkb
	```
- 链接
	- [Github MaxKB](https://github.com/1Panel-dev/MaxKB)

- 账号  
	用户名:Admin; 密码:Maxkb123Guxing


## open-webui
- 简介  
  ollama客户端

- docker 

	```shell
	docker run -d -p 3010:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
	```

- 账号  
	用户名:813102522@qq.com; 密码:123456

- 链接  
  - [openwebui](https://docs.openwebui.com/)

## lobe-chat
- 简介  
  生成式AI客户端，可连接本地ollama和其它开源大模型
- docker 

	```shell
	docker run -d -p 3210:3210 -e OPENAI_API_KEY=sk-xuan -e ACCESS_CODE=lobe66 --name lobe-chat  lobehub/lobe-chat
	```

## 配置相关

- docker中若使用本机的ollama，需要配置为
  ```text
  http://host.docker.internal:11434
  ```
## draw.io

```docker
docker run -d --name="draw" -p 8081:8080 -p 8443:8443 fjudith/draw.io
```

## ollama知识

- 环境变量

使用 "ollama serve" 启动时，可以看到
```test
OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST: OLLAMA_KEEP_ALIVE:600 OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS: OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[* http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR:C:\\Users\\16336\\AppData\\Local\\Programs\\Ollama\\ollama_runners OLLAMA_TMPDIR:
```
这里面就是环境变量，可以自己设置到PC的用户变量中

|字段|默认值|含义|
|--|--|--|
|OLLAMA_DEBUG|false||
|OLLAMA_FLASH_ATTENTION|false||
|OLLAMA_HOST|||
|OLLAMA_KEEP_ALIVE|5m|控制模型在内存中的存活时间,默认为5分钟|
|OLLAMA_LLM_LIBRARY|||
|OLLAMA_MAX_LOADED_MODELS|1|限制了Ollama可以同时加载的模型数量。|
|OLLAMA_MAX_QUEUE|512||
|OLLAMA_MAX_VRAM|||
|OLLAMA_MODELS|||
|OLLAMA_NOHISTORY|false||
|OLLAMA_NOPRUNE|||
|OLLAMA_NUM_PARALLEL|1|可以同时处理的用户请求数量,若设置4，则可以同时处理两个用户的请求|
|OLLAMA_ORIGINS|||
|OLLAMA_RUNNERS_DIR|||
|OLLAMA_PORT|11434|Ollama的默认端口|

- 其它参数设置

```shell
/set parameter num_ctx 4096 # 设置令牌大小，默认2048
```

## 其它知识库

- [https://github.com/langgenius/dify](https://github.com/langgenius/dify)

- [https://github.com/sugarforever/chat-ollama](https://github.com/sugarforever/chat-ollama)

- [Reor](https://www.reorproject.org/)

- [mrdoc]() 

- [http://draw.io]()


## ollama资料

- [API 有效参数及其值](https://ollama.fan/reference/modelfile/#valid-parameters-and-values)
- [Ollama 可以设置的环境变量](https://blog.csdn.net/engchina/article/details/138743634)